{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"protoconf","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Modern services are comprised of many dynamic variables, that need to be changed regularly. Today, the process is unstructured and error prone. From ML model variables, kill switches, gradual rollout configuration, A/B experiment configuration and more - developers want their code to allow to be configured to the finer details.</p> <p>Protoconf is a modern approach to software configuration, inspired by Facebook's Configerator.</p> <p>Using Protoconf enables:</p> <ul> <li>Code review for configuration changes   Enables the battle tested flow of pull-request &amp; code-review. Configuration auditing out of the box (who did what, when?). The repository is the source of truth for the configuration deployed to production.</li> <li>No service restart required to pick up changes   Instant delivery of configuration updates. Encourages writing software that doesn't know downtime.</li> <li>Clear representation of complex configuration   Write configuration in Starlark (a Python dialect), no more copying &amp; pasting from huge JSON files.</li> <li>Automated validation   Config follows a fully-typed (Protobuf) schema. This allows writing validation code in Starlark, to verify your configuration before it is committed.</li> </ul>"},{"location":"#what-is-protoconf","title":"What is protoconf","text":"<p>Protoconf is a configuration management framework. We call it a framework because it provides a platform to manage the entire life cycle of configuration files (configs). Protoconf is a tool to aid in the specification and distribution of configs. The goals of specification are to be robust, composable, and less error-prone. The goals of distribution are to reach all of your machines quickly, reliably, and to be highly available even in disaster scenarios.</p>"},{"location":"#when-should-you-use-protoconf","title":"When should you use Protoconf?","text":"<ul> <li> You need to update and distribute configuration dynamically, often to a large number of hosts or services.</li> <li> You want to write your configuration with code.</li> <li> You need change history.</li> <li> You want to code review config changes.</li> <li> You want validation that config changes conform to a schema and do not violate invariants that you define.</li> <li> You want to canary (test) config changes before distributing them to production.</li> <li> You can tolerate eventual consistency; config updates are not atomic w.r.t. different consumers.</li> <li> You don't need config updates to propagate to your consumers within a certain SLA.</li> <li> Your configs are reasonably small</li> <li> You don't need very frequent config updates, more than about once every 5 mins.</li> </ul>"},{"location":"#how-protoconf-works","title":"How Protoconf works","text":""},{"location":"#configuration-update-flow","title":"Configuration update flow","text":""},{"location":"#how-this-looks-from-the-services-eyes","title":"How this looks from the service's eyes","text":"<p>This is roughly how configuration is consumed by a service. This paradigm encourages you to write software that can reconfigure itself in runtime rather than require a restart:</p> Python <pre><code>#!/usr/bin/env python\nimport grpc\nfrom v1.protoconf_service_pb2_grpc import ProtoconfServiceStub\nfrom v1.protoconf_service_pb2 import ConfigSubscriptionRequest\nfrom myproject.myconfig_pb2 import MyConfig\n\nchannel = grpc.insecure_channel(\"localhost:4300\")\nstub = ProtoconfServiceStub(channel)\n\nconfig = MyConfig()\nfor update in stub.SubscribeForConfig(\n        ConfigSubscriptionRequest(path=\"myproject/myconfig\")):\n\n    # Override `config`\n    update.value.Unpack(config)\n    print(config)\n</code></pre> <p>As Protoconf uses Protobuf and gRPC, it supports delivering configuration to all major languages. See also: Protobuf overview.</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>Prerequisite for this guide:</p> <ul> <li>Knowledge in Python</li> <li>Familiarity with Protobuf and gRPC</li> </ul>"},{"location":"getting-started/#define-your-first-config","title":"Define your first config","text":"<p>The first step will be to define the config struct in <code>protobuf</code>. The <code>protobuf</code> file will be used to generate a marshaler of in the language of choice which can be used alongside the gRPC client to pull configs from the <code>protoconf agent</code> gRPC endpoint.</p> <pre><code>// file: ./src/myproject/myconfig.proto\nsyntax = \"proto3\";\n\nmessage MyConfig {\nuint32 connection_timeout = 1;\nuint32 max_retries = 2;\nNestedStruct another_struct = 3;\n}\n\nmessage NestedStruct {\nstring hello_world = 1;\n}\n</code></pre>"},{"location":"getting-started/#code-your-config","title":"Code your config","text":"<p>Create a <code>.pconf</code> file to populate the config struct with the required values.</p> <pre><code>\"\"\"\nfile: ./src/myproject/myconfig.pconf\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\", \"NestedStruct\")\n\ndef main():\n    return MyConfig(\n        connection_timeout=5,\n        max_retries=5,\n        another_struct=NestedStruct(\n            hello_world=\"Hello World!\"\n        )\n    )\n</code></pre>"},{"location":"getting-started/#compile-and-check-results","title":"Compile and check results","text":"<p>Our working directory is now ready to be compiled. Run <code>protoconf compile .</code>. The compiler will create a new file under <code>materialized_configs/myproject/myconfig.materialized_JSON</code> which can be used to validate the result of the config.</p> <pre><code>// file: materialized_configs/myproject/myconfig.materialized_JSON\n{\n\"protoFile\": \"myproject/myconfig.proto\",\n\"value\": {\n\"@type\": \"type.googleapis.com/MyConfig\",\n\"connectionTimeout\": 5,\n\"maxRetries\": 5,\n\"anotherStruct\": {\n\"helloWorld\": \"Hello World!\"\n}\n}\n}\n</code></pre>"},{"location":"getting-started/#add-validators","title":"Add validators","text":"<p>You might want to make sure no one can accidentally reduce the <code>connection_timeout</code> config below <code>3</code>. If he wish to do so, he can add a validator to the <code>MyConfig</code> struct:</p> <pre><code>\"\"\"\nfile: ./src/myproject/myconfig.proto-validator\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\")\n\ndef validate_connection_timeout(config):\n    if config.connection_timeout &lt;= 3:\n        fail(\"connection_timeout must be 3 or higher, got: %d\" % config.connection_timeout)\n\nadd_validator(MyConfig, validate_connection_timeout)\n</code></pre>"},{"location":"getting-started/#consume-your-config-locally","title":"Consume your config locally","text":"<p>To test his configs locally, you can run <code>protoconf agent -dev .</code> The agent is now running and listening on <code>0.0.0.0:4300</code> and ready to accept gRPC calls.</p> <p>Install the <code>grpc</code> and <code>protobuf</code> tools to generate the <code>stub</code> code to communicate with the protoconf gRPC agent.</p> <pre><code>$ pip install grpcio-tools\n$ python -m grpc_tools.protoc -Isrc --python_out=. --grpc_python_out=. ./src/myproject/myconfig.proto\n$ git clone https://github.com/protoconf/protoconf.git\n$ python -m grpc_tools.protoc -Iprotoconf/agent/api/proto/ --python_out=. --grpc_python_out=. protoconf/agent/api/proto/v1/protoconf_service.proto\n</code></pre> <p>Write a simple python code that will use the generated code to communicate with the agent. <pre><code>#!/usr/bin/env python\nimport grpc\nfrom v1.protoconf_service_pb2_grpc import ProtoconfServiceStub\nfrom v1.protoconf_service_pb2 import ConfigSubscriptionRequest\nfrom myproject.myconfig_pb2 import MyConfig\n\nchannel = grpc.insecure_channel(\"localhost:4300\")\nstub = ProtoconfServiceStub(channel)\n\nconfig = MyConfig()\nfor update in stub.SubscribeForConfig(ConfigSubscriptionRequest(path=\"myproject/myconfig\")):\n    update.value.Unpack(config)\n    print(config)\n</code></pre></p> <p>Run the python code and make a change to the <code>./src/myproject/myconfig.pconf</code>. After running <code>protoconf compile .</code> again, you will see the config changes in your running software.</p>"},{"location":"getting-started/#prepare-for-production","title":"Prepare for Production","text":"<p>Use a supported KV store to release the config to production. The supported storages are: Consul, Etcd or Zookeeper.</p> <pre><code>$ consul agent -dev &amp;\n$ protoconf insert -store consul -store-address localhost:8500 . myproject/myconfig\n</code></pre>"},{"location":"getting-started/#run-the-agent-in-production-mode","title":"Run the agent in production mode","text":"<pre><code>$ protoconf agent -store consul -store-address localhost:8500\n</code></pre> <p>Run your code the same way as step 5. Then make a change, compile and run the <code>protoconf insert</code> command from step 6 again.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#on-linuxmacos","title":"On Linux/MacOS","text":"<pre><code>export PROTOCONF_VERSION=\"0.1.5\"\nexport PROTOCONF_OS=$(uname | tr '[A-Z]' '[a-z]')\n# change to \"arm64\" if needed\nexport PROTOCONF_ARCH=\"amd64\"\ncurl -LO https://github.com/protoconf/protoconf/releases/download/${PROTOCONF_VERSION}/protoconf-${PROTOCONF_OS}-${PROTOCONF_ARCH}-${PROTOCONF_VERSION}.tar.gz\nsudo tar xvf protoconf-${PROTOCONF_OS}-${PROTOCONF_ARCH}-${PROTOCONF_VERSION}.tar.gz -C /usr/local/bin\n</code></pre>"},{"location":"installation/#on-windows","title":"On Windows","text":"<p>Download from the github releases page.</p>"},{"location":"installation/#validate-the-installation","title":"Validate the installation","text":"<pre><code>$ protoconf\n2020/04/26 10:16:59 proto: duplicate proto type registered: v1.ConfigSubscriptionRequest\n2020/04/26 10:16:59 proto: duplicate proto type registered: v1.ConfigUpdate\nUsage: protoconf [--version] [--help] &lt;command&gt; [&lt;args&gt;]\n\nAvailable commands are:\n    agent      Runs a Protoconf agent\n    compile    Compile configs\n    exec       Watches keys and execute on changes\n    import\n    insert     Insert a materialized config to the key-value store\n    mutate     Write to mutation server\n    serve      Runs a server\n</code></pre>"},{"location":"multiple-outputs/","title":"Multiple outputs","text":"<p>Sometimes, we want to generate multiple configs from a single file. for this, we can use the <code>.mpconf</code>.</p> <p><code>protoconf</code> expects <code>.mpconf</code>'s <code>main()</code> function to return a <code>dict</code> with a <code>string</code> as the key and a <code>proto.Message</code> as the value.</p> <p>Example:</p> <pre><code>// file: src/myservice/myconfig.proto\nsyntax = \"proto3\";\nmessage MyConfig {\nstring name = 1;\nuint32 timeout = 2;\n}\n</code></pre> <pre><code>\"\"\"\nfile: ./src/myservice/outputs.mpconf\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\")\n\nout = {}\n\nfor i in range(5):\n    out[\"config%d\" % i] = MyConfig(name=\"config%d\" % i, timeout=i * 3)\n\ndef main():\n    return out\n</code></pre> <p>Now, when you compile your configs, you will see multiple outputs</p> <pre><code>$ protoconf compile .\n$ find materialized_config/myservice\nmaterialized_config/myservice\nmaterialized_config/myservice/outputs\nmaterialized_config/myservice/outputs/config4.materialized_JSON\nmaterialized_config/myservice/outputs/config1.materialized_JSON\nmaterialized_config/myservice/outputs/config0.materialized_JSON\nmaterialized_config/myservice/outputs/config3.materialized_JSON\nmaterialized_config/myservice/outputs/config2.materialized_JSON\n</code></pre>"},{"location":"mutation-rpc/","title":"Mutation RPC usage","text":"<p>One of the core principals of <code>protoconf</code> is the ability to mutate configs via an API (or RPC). This allows humans and machines work together on the same configuration codebase. <code>protoconf</code> allow humans to code the logic, while machines can only change values via the RPC.</p>"},{"location":"mutation-rpc/#create-a-dummy-config","title":"Create a dummy config","text":"<pre><code>// file: ./src/myservice/myconfig.proto\nsyntax = \"proto3\";\nmessage MyConfig {\nstring name = 1;\nuint32 timeout = 2;\n}\n</code></pre> <pre><code>\"\"\"\nfile: ./src/myservice/default.pconf\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\")\n\nconfig = MyConfig(name=\"config\")\n\ndef main():\n    return config\n</code></pre> <pre><code>$ protoconf compile .\n</code></pre>"},{"location":"mutation-rpc/#create-a-post-mutation-script","title":"Create a post-mutation script","text":"<pre><code>$ echo '#!/bin/bash\\nprotoconf compile .' &gt; post.sh\n$ chmod +x post.sh\n</code></pre>"},{"location":"mutation-rpc/#run-the-mutation-server-in-the-background","title":"Run the mutation server in the background","text":"<pre><code>$ protoconf serve -post ./post.sh . &amp;\n</code></pre> <p>Now we will use the <code>protoconf mutate</code> command to hit the mutation RPC <pre><code>$ protoconf mutate -path myservice/mutation -proto myservice/myconfig.proto -msg MyConfig -field timeout=3\n</code></pre></p> <p>You will now notice a new file created under <code>mutable_config</code></p> <pre><code>$ find mutable_config\nmutable_config\nmutable_config/myservice\nmutable_config/myservice/mutation.materialized_JSON\n</code></pre>"},{"location":"mutation-rpc/#load-the-mutated-values","title":"load the mutated values","text":"<pre><code>\"\"\"\nfile: ./src/myservice/default.pconf\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\")\nload(\"mutable:myservice/mutation\", \"value\")\n\nconfig = MyConfig(name=\"config\", timeout=value.timeout)\n\ndef main():\n    return config\n</code></pre> <p>Run the <code>protoconf mutate</code> command again with different value and watch how your configs changes.</p>"},{"location":"mutation-rpc/#next-steps","title":"Next steps","text":""},{"location":"mutation-rpc/#running-in-production","title":"Running in production","text":"<p>The <code>protoconf serve</code> command accepts <code>-pre</code> and <code>-post</code> scripts which should be used for preparing the ground for writing the mutation (<code>-pre</code>) and followup actions to run after writing the mutation (<code>-post</code>). </p> <p>Both scripts will run by <code>protoconf serve</code> on every mutation. The scripts will be receiveing a <code>metadata</code> string as its first argument (<code>$1</code> in <code>bash</code>) and can be used to pass metadata from the initiator of the rpc to the script, This can be used to pass a token for github to validate the initiator or to pass more context to be added to the commit message.</p> <p>These scripts should handle the <code>git</code> lifecycle of the mutation (setting the workspace to latest ref, and push the result after the writing done.)</p> <p>compiling the configs should be part of the <code>-post</code> script.</p> <p>When running in HA, you can use these scripts to acquire a lock from <code>consul</code>/<code>etcd</code>.</p>"},{"location":"mutation-rpc/#using-grpc","title":"Using gRPC","text":"<p>The mutation proto is available here.</p>"},{"location":"protoconf-exec/","title":"Using protoconf exec","text":"<p>It's very likely that your infra relies on many components which does not have native <code>protoconf</code> integration. You can still use protoconf to code their config and use some wrappers around the process you are running in order to write and reload the config. <code>protoconf exec</code> aims to be a general purpose way to do so (still WIP and many features are not implemented)</p>"},{"location":"protoconf-exec/#import-the-exec-config-to-your-workspace","title":"Import the exec config to your workspace","text":"<pre><code>$ mkdir -p src/exec\ncurl -Lo src/exec/exec_config.proto https://raw.githubusercontent.com/protoconf/protoconf/v0.1.3/exec/config/exec_config.proto\n</code></pre>"},{"location":"protoconf-exec/#create-a-dummy-proto-and-config","title":"Create a dummy proto and config","text":"<pre><code>// file: ./src/myservice/myconfig.proto\nsyntax = \"proto3\";\nmessage MyConfig {\nstring name = 1;\nuint32 timeout = 2;\n}\n</code></pre> <pre><code>\"\"\"\nfile: ./src/myservice/myconfig.pconf\n\"\"\"\nload(\"myconfig.proto\", \"MyConfig\")\n\nconfig = MyConfig(name=\"test\", timeout=3)\n\ndef main():\n    return config\n</code></pre>"},{"location":"protoconf-exec/#create-an-exec-config","title":"Create an <code>exec</code> config","text":"<pre><code>\"\"\"\nGenerates tf.json files under ./tfconfigs\n\"\"\"\nload(\n    \"//exec/exec_config.proto\",\n    \"Config\",\n    \"WatcherConfig\",\n    \"Action\",\n    \"ActionTypeWriteToFile\",\n)\n\nconfigs = [\n    \"mysservice/myconfig\"\n]\n\n\ndef main():\n    return Config(\n        items=[\n            WatcherConfig(\n                path=path,\n                proto_file=\"myservice/myconfig.proto\",\n                actions=[\n                    Action(file=ActionTypeWriteToFile(path=\"tfconfigs/%s.json\" % path))\n                ],\n            )\n            for path in configs\n        ]\n    )\n</code></pre>"},{"location":"structuring-your-code/","title":"Structuring your code","text":"<p>Sometimes, when we use <code>protoconf</code> we will want to write helpers functions and global constants that we might want to include in multiple configs. We can define those in <code>.pinc</code> files.</p> <p><code>.pinc</code> files are starlark code which doesn't produce configs (doesn't evaluate the <code>main()</code> function).</p> <p>Example:</p> <pre><code>\"\"\"\nfile: ./src/helpers.pinc\n\"\"\"\nPROTOCONF_VERSION=\"0.1.3\"\n\ndef format_name(person):\n    # assumes `person` is a proto message that have `first_name` and `last_name`\n    return \"%s %s\" % (person.first_name, person.last_name)\n</code></pre> <p>We can now load the variables and functions in this file to another <code>starlark</code> file (<code>pinc</code>, <code>.pconf</code> or <code>.mpconf</code>)</p> <pre><code>load(\"//helpers.pinc\", \"PROTOCONF_VERSION\", \"format_name\")\n</code></pre>"},{"location":"integrations/terraform/","title":"Protoconf integration with Terraform","text":""},{"location":"integrations/terraform/#prerequists","title":"Prerequists","text":"<ul> <li>The <code>terraform</code> binray in your <code>$PATH</code></li> <li>The <code>protoconf</code> binary in your <code>$PATH</code></li> </ul>"},{"location":"integrations/terraform/#prepare","title":"Prepare","text":"<p>Create a <code>providers.tf</code> file containing the providers declarations you need.</p> <pre><code>provider \"random\" {}\nprovider \"tls\" {}\n</code></pre>"},{"location":"integrations/terraform/#initialize-terraform","title":"Initialize Terraform","text":"<pre><code>$ terraform init\n</code></pre>"},{"location":"integrations/terraform/#generate-the-terraform-protos","title":"Generate the terraform protos","text":"<pre><code>$ protoconf import terraform\n</code></pre> <p>Validate the outputs</p> <pre><code>$ find src/terraform\nsrc/terraform\nsrc/terraform/v1\nsrc/terraform/v1/terraform.proto\nsrc/terraform/v1/meta.proto\nsrc/terraform/tls\nsrc/terraform/tls/datasources\nsrc/terraform/tls/datasources/v3\nsrc/terraform/tls/datasources/v3/public.proto\nsrc/terraform/tls/datasources/v3/certificate.proto\nsrc/terraform/tls/resources\nsrc/terraform/tls/resources/v3\nsrc/terraform/tls/resources/v3/private.proto\nsrc/terraform/tls/resources/v3/self.proto\nsrc/terraform/tls/resources/v3/cert.proto\nsrc/terraform/tls/resources/v3/locally.proto\nsrc/terraform/tls/provider\nsrc/terraform/tls/provider/v3\nsrc/terraform/tls/provider/v3/tls.proto\nsrc/terraform/random\nsrc/terraform/random/resources\nsrc/terraform/random/resources/v3\nsrc/terraform/random/resources/v3/password.proto\nsrc/terraform/random/resources/v3/integer.proto\nsrc/terraform/random/resources/v3/string.proto\nsrc/terraform/random/resources/v3/pet.proto\nsrc/terraform/random/resources/v3/shuffle.proto\nsrc/terraform/random/resources/v3/id.proto\nsrc/terraform/random/resources/v3/uuid.proto\nsrc/terraform/random/provider\nsrc/terraform/random/provider/v3\nsrc/terraform/random/provider/v3/random.proto\n</code></pre> <p>The <code>src/terraform/terraform.proto</code> should looks like this:</p> <pre><code>syntax = \"proto3\";\n\npackage terraform.v1;\n\nimport \"terraform/random/provider/v3/random.proto\";\n\nimport \"terraform/random/resources/v3/id.proto\";\n\nimport \"terraform/random/resources/v3/integer.proto\";\n\nimport \"terraform/random/resources/v3/password.proto\";\n\nimport \"terraform/random/resources/v3/pet.proto\";\n\nimport \"terraform/random/resources/v3/shuffle.proto\";\n\nimport \"terraform/random/resources/v3/string.proto\";\n\nimport \"terraform/random/resources/v3/uuid.proto\";\n\nimport \"terraform/tls/datasources/v3/certificate.proto\";\n\nimport \"terraform/tls/datasources/v3/public.proto\";\n\nimport \"terraform/tls/provider/v3/tls.proto\";\n\nimport \"terraform/tls/resources/v3/cert.proto\";\n\nimport \"terraform/tls/resources/v3/locally.proto\";\n\nimport \"terraform/tls/resources/v3/private.proto\";\n\nimport \"terraform/tls/resources/v3/self.proto\";\n\nmessage Terraform {\nResources resource = 1;\n\nDatasources data = 2;\n\nProviders provider = 3;\n\nmap&lt;string, Variable&gt; variable = 4;\n\nmap&lt;string, Output&gt; output = 5;\n\nmap&lt;string, string&gt; locals = 6;\n\nModule module = 7;\n\nTerraformSettings terraform = 8;\n\nmessage Resources {\nmap&lt;string, terraform.random.resources.v3.RandomId&gt; random_id = 1 [json_name = \"random_id\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomInteger&gt; random_integer = 2 [json_name = \"random_integer\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomPassword&gt; random_password = 3 [json_name = \"random_password\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomPet&gt; random_pet = 4 [json_name = \"random_pet\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomShuffle&gt; random_shuffle = 5 [json_name = \"random_shuffle\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomString&gt; random_string = 6 [json_name = \"random_string\"];\n\nmap&lt;string, terraform.random.resources.v3.RandomUuid&gt; random_uuid = 7 [json_name = \"random_uuid\"];\n\nmap&lt;string, terraform.tls.resources.v3.TlsCertRequest&gt; tls_cert_request = 8 [json_name = \"tls_cert_request\"];\n\nmap&lt;string, terraform.tls.resources.v3.TlsLocallySignedCert&gt; tls_locally_signed_cert = 9 [json_name = \"tls_locally_signed_cert\"];\n\nmap&lt;string, terraform.tls.resources.v3.TlsPrivateKey&gt; tls_private_key = 10 [json_name = \"tls_private_key\"];\n\nmap&lt;string, terraform.tls.resources.v3.TlsSelfSignedCert&gt; tls_self_signed_cert = 11 [json_name = \"tls_self_signed_cert\"];\n}\n\nmessage Datasources {\nmap&lt;string, terraform.tls.datasources.v3.TlsCertificate&gt; tls_certificate = 1 [json_name = \"tls_certificate\"];\n\nmap&lt;string, terraform.tls.datasources.v3.TlsPublicKey&gt; tls_public_key = 2 [json_name = \"tls_public_key\"];\n}\n\nmessage Providers {\nrepeated terraform.random.provider.v3.Random random = 1;\n\nrepeated terraform.tls.provider.v3.Tls tls = 2;\n}\n\nmessage Variable {\nstring type = 1;\n\nstring description = 2;\n\nstring default = 3;\n}\n\nmessage Output {\nstring value = 1;\n}\n\nmessage Module {\n}\n\nmessage TerraformSettings {\nstring required_version = 1 [json_name = \"required_version\"];\n\nmap&lt;string, Provider&gt; required_providers = 2 [json_name = \"required_providers\"];\n\nBackend backend = 3;\n\nmessage Provider {\nstring source = 1;\n\nstring version = 2;\n}\n\nmessage Backend {\noneof config {\nBackendLocal local = 1;\n\nBackendRemote remote = 2;\n\nBackendS3 s3 = 3;\n}\n\nmessage BackendLocal {\nstring path = 1;\n\nstring workspace_dir = 2 [json_name = \"workspace_dir\"];\n}\n\nmessage BackendRemote {\n//(Optional) The remote backend hostname to connect to. Defaults to app.terraform.io.\nstring hostname = 1;\n\n//(Required) The name of the organization containing the targeted workspace(s).\nstring organization = 2;\n\n//(Optional) The token used to authenticate with the remote backend. We recommend omitting the token from the configuration, and instead using `terraform login` or manually configuring `credentials` in the CLI config file.\nstring token = 3;\n\n//(Required) A block specifying which remote workspace(s) to use. The workspaces block supports the following keys\nWorkspace workspaces = 4;\n\nmessage Workspace {\n//(Optional) The full name of one remote workspace. When configured, only the default workspace can be used. This option conflicts with prefix.\nstring name = 1;\n\n//(Optional) A prefix used in the names of one or more remote workspaces, all of which can be used with this configuration. The full workspace names are used in Terraform Cloud, and the short names (minus the prefix) are used on the command line for Terraform CLI workspaces. If omitted, only the default workspace can be used. This option conflicts with name.\nstring prefix = 2;\n}\n}\n\nmessage BackendS3 {\nstring region = 1;\n\nstring access_key = 2 [json_name = \"access_key\"];\n\nstring secret_key = 3 [json_name = \"secret_key\"];\n\nstring iam_endpoint = 4 [json_name = \"iam_endpoint\"];\n\nstring max_retries = 5 [json_name = \"max_retries\"];\n\nstring profile = 6;\n\nstring shared_credentials_file = 7 [json_name = \"shared_credentials_file\"];\n\nstring skip_credentials_validation = 8 [json_name = \"skip_credentials_validation\"];\n\nstring skip_region_validation = 9 [json_name = \"skip_region_validation\"];\n\nstring skip_metadata_api_check = 10 [json_name = \"skip_metadata_api_check\"];\n\nstring sts_endpoint = 11 [json_name = \"sts_endpoint\"];\n\nstring token = 12;\n\nstring assume_role_duration_seconds = 13 [json_name = \"assume_role_duration_seconds\"];\n\nstring assume_role_policy = 14 [json_name = \"assume_role_policy\"];\n\nstring assume_role_policy_arns = 15 [json_name = \"assume_role_policy_arns\"];\n\nstring assume_role_tags = 16 [json_name = \"assume_role_tags\"];\n\nstring assume_role_transitive_tag_keys = 17 [json_name = \"assume_role_transitive_tag_keys\"];\n\nstring external_id = 18 [json_name = \"external_id\"];\n\nstring role_arn = 19 [json_name = \"role_arn\"];\n\nstring session_name = 20 [json_name = \"session_name\"];\n\nstring bucket = 21;\n\nstring key = 22;\n\nstring acl = 23;\n\nstring encrypt = 24;\n\nstring endpoint = 25;\n\nstring force_path_style = 26 [json_name = \"force_path_style\"];\n\nstring kms_key_id = 27 [json_name = \"kms_key_id\"];\n\nstring sse_customer_key = 28 [json_name = \"sse_customer_key\"];\n\nstring workspace_key_prefix = 29 [json_name = \"workspace_key_prefix\"];\n\nstring dynamodb_endpoint = 30 [json_name = \"dynamodb_endpoint\"];\n\nstring dynamodb_table = 31 [json_name = \"dynamodb_table\"];\n}\n}\n}\n}\n</code></pre>"},{"location":"integrations/terraform/#create-a-tfpconf-file","title":"Create a <code>.tf.pconf</code> file","text":"<pre><code># vim: filetype=python\n# ./src/tfdemo/tfdemo.tf.pconf\nload(\"//terraform/v1/terraform.proto\", \"Terraform\")\nload(\"//terraform/random/provider/v3/random.proto\", \"Random\")\nload(\"//terraform/random/resources/v3/pet.proto\", \"RandomPet\")\n\ntf = Terraform(\n    provider=Terraform.Providers(random=[Random()]),\n    resource=Terraform.Resources(),\n    output={},\n)\n\ntf.resource.random_pet[\"my_dog_name\"] = RandomPet()\ntf.output[\"my_dog_name\"] = Terraform.Output(value=\"${random_pet.my_dog_name.id}\")\n\n\ndef main():\n    return tf\n</code></pre>"},{"location":"integrations/terraform/#compile-the-config","title":"compile the config","text":"<pre><code>$ protoconf compile .\n</code></pre> <p>Check the output</p> <pre><code>cat materialized_config/tfdemo/tfdemo.tf.materialized_JSON\n</code></pre> <pre><code>{\n\"protoFile\": \"terraform/terraform.proto\",\n\"value\": {\n\"@type\": \"type.googleapis.com/terraform.Terraform\",\n\"output\": {\n\"my_dog_name\": {\n\"value\": \"${random_pet.my_dog_name.id}\"\n}\n},\n\"provider\": {\n\"random\": [{}]\n},\n\"resource\": {\n\"random_pet\": {\n\"my_dog_name\": {}\n}\n}\n}\n}\n</code></pre>"},{"location":"integrations/terraform/#prepare-to-run-terraform","title":"prepare to run terraform","text":"<pre><code>$ mkdir tf\n$ cat materialized_config/tfdemo/tfdemo.tf.materialized_JSON | jq '.value | del(.[\"@type\"])' &gt; tf/test.tf.json\n$ terraform -chdir=tf init\n</code></pre> <pre><code>$ terraform -chdir=tf plan\n\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # random_pet.my_dog_name will be created\n+ resource \"random_pet\" \"my_dog_name\" {\n+ id        = (known after apply)\n+ length    = 2\n+ separator = \"-\"\n}\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nChanges to Outputs:\n  + my_dog_name = (known after apply)\n\n------------------------------------------------------------------------\n\nNote: You didn't specify an \"-out\" parameter to save this plan, so Terraform\ncan't guarantee that exactly these actions will be performed if\n\"terraform apply\" is subsequently run.\n</code></pre> <pre><code>$ terraform -chdir=tf apply -auto-approve\nrandom_pet.my_dog_name: Creating...\nrandom_pet.my_dog_name: Creation complete after 0s [id=key-zebra]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n\nOutputs:\n\nmy_dog_name = \"key-zebra\"\n</code></pre>"},{"location":"integrations/terraform_kubernetes/","title":"Protoconf integration with Terraform for managing Kubernetes resources","text":""},{"location":"integrations/terraform_kubernetes/#prerequisites","title":"Prerequisites","text":"<ul> <li>The <code>terraform</code> binary in your <code>$PATH</code></li> <li>The <code>protoconf</code> binary in your <code>$PATH</code></li> </ul>"},{"location":"integrations/terraform_kubernetes/#prepare","title":"Prepare","text":"<p>Create a <code>providers.tf</code> file containing the providers declarations you need.</p> <pre><code>provider \"kubernetes\" {}\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#initialize-terraform","title":"Initialize Terraform","text":"<pre><code>$ terraform init\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#generate-the-terraform-protos","title":"Generate the terraform protos","text":"<pre><code>$ protoconf import terraform\n</code></pre> <p>Validate the outpus</p> <pre><code>$ find src/terraform\nsrc/terraform\nsrc/terraform/v1\nsrc/terraform/v1/terraform.proto\nsrc/terraform/v1/meta.proto\nsrc/terraform/kubernetes\nsrc/terraform/kubernetes/datasources\nsrc/terraform/kubernetes/datasources/v2\nsrc/terraform/kubernetes/datasources/v2/namespace.proto\nsrc/terraform/kubernetes/datasources/v2/all.proto\nsrc/terraform/kubernetes/datasources/v2/persistent.proto\nsrc/terraform/kubernetes/datasources/v2/storage.proto\nsrc/terraform/kubernetes/datasources/v2/service.proto\nsrc/terraform/kubernetes/datasources/v2/ingress.proto\nsrc/terraform/kubernetes/datasources/v2/config.proto\nsrc/terraform/kubernetes/datasources/v2/pod.proto\nsrc/terraform/kubernetes/datasources/v2/secret.proto\nsrc/terraform/kubernetes/resources\nsrc/terraform/kubernetes/resources/v2\nsrc/terraform/kubernetes/resources/v2/mutating.proto\nsrc/terraform/kubernetes/resources/v2/priority.proto\nsrc/terraform/kubernetes/resources/v2/namespace.proto\nsrc/terraform/kubernetes/resources/v2/validating.proto\nsrc/terraform/kubernetes/resources/v2/stateful.proto\nsrc/terraform/kubernetes/resources/v2/manifest.proto\nsrc/terraform/kubernetes/resources/v2/cluster.proto\nsrc/terraform/kubernetes/resources/v2/api.proto\nsrc/terraform/kubernetes/resources/v2/job.proto\nsrc/terraform/kubernetes/resources/v2/persistent.proto\nsrc/terraform/kubernetes/resources/v2/daemonset.proto\nsrc/terraform/kubernetes/resources/v2/cron.proto\nsrc/terraform/kubernetes/resources/v2/role.proto\nsrc/terraform/kubernetes/resources/v2/deployment.proto\nsrc/terraform/kubernetes/resources/v2/storage.proto\nsrc/terraform/kubernetes/resources/v2/csi.proto\nsrc/terraform/kubernetes/resources/v2/endpoints.proto\nsrc/terraform/kubernetes/resources/v2/service.proto\nsrc/terraform/kubernetes/resources/v2/ingress.proto\nsrc/terraform/kubernetes/resources/v2/default.proto\nsrc/terraform/kubernetes/resources/v2/certificate.proto\nsrc/terraform/kubernetes/resources/v2/replication.proto\nsrc/terraform/kubernetes/resources/v2/limit.proto\nsrc/terraform/kubernetes/resources/v2/horizontal.proto\nsrc/terraform/kubernetes/resources/v2/resource.proto\nsrc/terraform/kubernetes/resources/v2/network.proto\nsrc/terraform/kubernetes/resources/v2/config.proto\nsrc/terraform/kubernetes/resources/v2/daemon.proto\nsrc/terraform/kubernetes/resources/v2/pod.proto\nsrc/terraform/kubernetes/resources/v2/secret.proto\nsrc/terraform/kubernetes/provider\nsrc/terraform/kubernetes/provider/v2\nsrc/terraform/kubernetes/provider/v2/kubernetes.proto\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#create-directory-for-the-starlark-configuration-file-pconf","title":"Create directory for the Starlark configuration file (.pconf)","text":"<pre><code>$ mkdir src/proto-kube/\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#create-the-starlark-configuration-file-pconf","title":"Create the Starlark configuration file (.pconf)","text":"<pre><code># vim: filetype=python\n# ./src/proto-kube/kube-pod.pconf\n\nload(\"//terraform/v1/terraform.proto\", \"Terraform\")\nload(\"//terraform/kubernetes/provider/v2/kubernetes.proto\", \"Kubernetes\")\nload(\"//terraform/kubernetes/resources/v2/pod.proto\", \"KubernetesPod\")\n\ntf = Terraform(\n    provider=Terraform.Providers(\n        kubernetes=[Kubernetes(config_path=\"/path/to/kubeconfig\")]\n    ),\n    resource=Terraform.Resources(),\n    output={},\n)\n\n\nname = KubernetesPod.Metadata(name=\"example-pod\")\nspec = KubernetesPod.Spec(\n    container=[KubernetesPod.Spec.Container(\n        name=\"test-container\",\n        image=\"centos/tools\",\n        command=[\"/bin/bash\", \"-c\", \"sleep 2000000000000\"],\n    )]\n)\n\ntf.resource.kubernetes_pod[\"my_pod\"] = KubernetesPod(metadata=name, spec=spec)\n\n\ndef main():\n    return tf\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#compile-the-config","title":"Compile the config","text":"<pre><code>$ protoconf compile .\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#check-the-json-output","title":"Check the json output","text":"<pre><code>cat materialized_config/proto-kube/kube-pod.materialized_JSON\n</code></pre> <pre><code>{\n\"protoFile\": \"terraform/terraform.proto\",\n\"value\": {\n\"@type\": \"type.googleapis.com/terraform.Terraform\",\n\"provider\": {\n\"kubernetes\": [\n{\n\"config_path\": \"/path/to/kubeconfig\"\n}\n]\n},\n\"resource\": {\n\"kubernetes_pod\": {\n\"my_pod\": {\n\"metadata\": {\n\"name\": \"example-pod\"\n},\n\"spec\": {\n\"container\": {\n\"command\": [\"/bin/bash\", \"-c\", \"sleep 2000000000000\"],\n\"image\": \"centos/tools\",\n\"name\": \"test-container\"\n}\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#prepare-to-run-terraform","title":"Prepare to run Terraform","text":""},{"location":"integrations/terraform_kubernetes/#create-terraform-working-directory","title":"Create Terraform working directory","text":"<pre><code>$ mkdir tf\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#process-json-required-by-terraform","title":"Process json required by Terraform","text":"<pre><code>$ cat materialized_config/proto-kube/kube-pod.materialized_JSON | \\\njq '.value | del(.[\"@type\"])' &gt; tf/proto-kube.tf.json\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#check-the-json-required-by-terraform","title":"Check the json required by Terraform","text":"<pre><code>$ cat tf/proto-kube.tf.json\n{\n\"provider\": {\n\"kubernetes\": [\n{\n\"config_path\": \"./kubeconfig\"\n}\n]\n},\n  \"resource\": {\n\"kubernetes_pod\": {\n\"my_pod\": {\n\"metadata\": {\n\"name\": \"example-pod\"\n},\n        \"spec\": {\n\"container\": {\n\"command\": [\n\"/bin/bash\",\n              \"-c\",\n              \"sleep 2000000000000\"\n],\n            \"image\": \"centos/tools\",\n            \"name\": \"test-container\"\n}\n}\n}\n}\n}\n}\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#run-terraform-init","title":"Run Terraform init","text":"<pre><code>$ cd tf\n~/tf $ terraform init\n\nInitializing the backend...\n\nInitializing provider plugins...\n- Finding latest version of hashicorp/kubernetes...\n- Installing hashicorp/kubernetes v2.3.2...\n- Installed hashicorp/kubernetes v2.3.2 (signed by HashiCorp)\n\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n\nTerraform has been successfully initialized!\n\nYou may now begin working with Terraform. Try running \"terraform plan\" to see\nany changes that are required for your infrastructure. All Terraform commands\nshould now work.\n\nIf you ever set or change modules or backend configuration for Terraform,\nrerun this command to reinitialize your working directory. If you forget, other\ncommands will detect it and remind you to do so if necessary.\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#run-terraform-plan","title":"Run Terraform plan","text":"<pre><code>~/tf $ terraform plan\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n[ ... ]\nPlan: 1 to add, 0 to change, 0 to destroy.\n\n\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre>"},{"location":"integrations/terraform_kubernetes/#run-terraform-apply","title":"Run Terraform apply","text":"<pre><code>~/tf $ terraform apply -auto-approve\n\nTerraform used the selected providers to generate the following execution plan. Resource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # kubernetes_pod.my_pod will be created\n+ resource \"kubernetes_pod\" \"my_pod\" {\n+ id = (known after apply)\n\n+ metadata {\n+ generation       = (known after apply)\n+ name             = \"example-pod\"\n+ namespace        = \"default\"\n+ resource_version = (known after apply)\n+ uid              = (known after apply)\n}\n\n+ spec {\n+ automount_service_account_token  = true\n+ dns_policy                       = \"ClusterFirst\"\n+ enable_service_links             = true\n+ host_ipc                         = false\n+ host_network                     = false\n+ host_pid                         = false\n+ hostname                         = (known after apply)\n+ node_name                        = (known after apply)\n+ restart_policy                   = \"Always\"\n+ service_account_name             = (known after apply)\n+ share_process_namespace          = false\n+ termination_grace_period_seconds = 30\n\n+ container {\n+ command                    = [\n+ \"/bin/bash\",\n                  + \"-c\",\n                  + \"sleep 2000000000000\",\n                ]\n+ image                      = \"centos/tools\"\n+ image_pull_policy          = (known after apply)\n+ name                       = \"test-container\"\n+ stdin                      = false\n+ stdin_once                 = false\n+ termination_message_path   = \"/dev/termination-log\"\n+ termination_message_policy = (known after apply)\n+ tty                        = false\n\n+ resources {\n+ limits   = (known after apply)\n+ requests = (known after apply)\n}\n}\n\n[ ... ]\n\nPlan: 1 to add, 0 to change, 0 to destroy.\nkubernetes_pod.my_pod: Creating...\nkubernetes_pod.my_pod: Still creating... [10s elapsed]\nkubernetes_pod.my_pod: Still creating... [20s elapsed]\nkubernetes_pod.my_pod: Still creating... [30s elapsed]\nkubernetes_pod.my_pod: Still creating... [40s elapsed]\nkubernetes_pod.my_pod: Still creating... [50s elapsed]\nkubernetes_pod.my_pod: Still creating... [1m0s elapsed]\nkubernetes_pod.my_pod: Still creating... [1m10s elapsed]\nkubernetes_pod.my_pod: Still creating... [1m20s elapsed]\nkubernetes_pod.my_pod: Still creating... [1m30s elapsed]\nkubernetes_pod.my_pod: Creation complete after 1m34s [id=default/example-pod]\n\nApply complete! Resources: 1 added, 0 changed, 0 destroyed.\n</code></pre>"}]}